# Bayesian-Analysis
This repository contains a collection of lab exercises focused on Bayesian analysis. Bayesian statistics is a powerful approach to inferential modeling that allows for uncertainty quantification and parameter estimation. The exercises in this repository cover various topics related to Bayesian analysis, including Markov Chain Monte Carlo (MCMC) methods, JAGS modeling, and posterior inference.

Lab Exercise 1: Introduction to Bayesian Statistics  
This lab exercise provides a foundational understanding of Bayesian statistics, including the concept of priors, likelihood, and posterior distributions.
It includes practical examples of Bayesian inference using R, showcasing how to estimate parameters and make predictions using the Bayesian framework.
The exercises explore basic probability distributions, conjugate priors, and posterior sampling using Metropolis-Hastings and Gibbs sampling algorithms.  

Lab Exercise 2: Monte Carlo Methods and Accept-Reject Sampling  
This lab exercise delves into Monte Carlo methods for Bayesian computation and sampling from complex probability distributions.
It introduces accept-reject sampling and demonstrates its implementation in R for generating samples from non-standard distributions.
Additionally, it covers the accept-reject method for estimating probabilities and using it to evaluate integrals.  

Lab Exercise 3: Markov Chain Monte Carlo (MCMC)  
This lab exercise focuses on the Markov Chain Monte Carlo (MCMC) technique, an essential tool for Bayesian inference and posterior sampling.
It provides hands-on experience with MCMC methods using R packages like rjags and coda.
The exercises cover MCMC algorithms like the Metropolis-Hastings algorithm and the Gibbs sampler for Bayesian parameter estimation and posterior exploration.  

Lab Exercise 4: Advanced Bayesian Modeling  
In this lab exercise, advanced Bayesian modeling techniques are explored, including hierarchical models and models with binary response data.
It covers topics such as hierarchical priors, individual gamma priors, and centering of covariates in Bayesian models.
The exercises showcase the use of JAGS (Just Another Gibbs Sampler) for building and fitting complex Bayesian models.
